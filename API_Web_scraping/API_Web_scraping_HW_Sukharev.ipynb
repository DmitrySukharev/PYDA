{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. \n",
    "### Обязательная часть\n",
    "Будем парсить страницу со свежими новостям на [habr.com/ru/all/](https://habr.com/ru/all/).\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>\n",
    "\n",
    "### Дополнительная часть (необязательная)\n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://habr.com/ru/all/'\n",
    "keywords = ['python', 'парсинг']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get(url).text, 'html.parser')    # Получаем главную страницу с новыми статьями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 23:58</td>\n",
       "      <td>Участвуем в соревновании по Data Science. Перв...</td>\n",
       "      <td>https://habr.com/ru/post/530628/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                              title  \\\n",
       "0  вчера в 23:58  Участвуем в соревновании по Data Science. Перв...   \n",
       "\n",
       "                               link  \n",
       "0  https://habr.com/ru/post/530628/  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задание 1.1, обязательная часть, только превью\n",
    "\n",
    "habr_previews_1 = pd.DataFrame()\n",
    "\n",
    "posts = soup.find_all('article', class_='post')    # Находим все статьи\n",
    "\n",
    "for post in posts:\n",
    "    if any(keyword in post.get_text().lower() for keyword in keywords):    # Проверка всех элементов поста (превью)\n",
    "        title = post.find('a', class_=\"post__title_link\").get_text()\n",
    "        date = post.find('span', class_=\"post__time\").get_text()\n",
    "        link = post.find('a', class_=\"post__title_link\").get('href')\n",
    "        row = {'date': date, 'title': title, 'link':link}\n",
    "        habr_previews_1 = pd.concat([habr_previews_1, pd.DataFrame([row])])\n",
    "        \n",
    "habr_previews_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 23:58</td>\n",
       "      <td>Участвуем в соревновании по Data Science. Перв...</td>\n",
       "      <td>https://habr.com/ru/post/530628/</td>\n",
       "      <td>Привет, Хабр!\\n\\r\\nДавно я не писал никаких ст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 22:15</td>\n",
       "      <td>Новые ограничения в использовании Docker Hub и...</td>\n",
       "      <td>https://habr.com/ru/company/gitlab/blog/530666/</td>\n",
       "      <td>Ни для кого уже не новость, что начиная с 2 но...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 19:23</td>\n",
       "      <td>ESP32 в окружении VSCode</td>\n",
       "      <td>https://habr.com/ru/post/530638/</td>\n",
       "      <td>В нескольких следующих статьях я хотел бы дета...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 18:30</td>\n",
       "      <td>Программа SmartData 2020</td>\n",
       "      <td>https://habr.com/ru/company/jugru/blog/530584/</td>\n",
       "      <td>\\nМы уже рассказывали Хабру, что новая SmartDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 16:07</td>\n",
       "      <td>CTF-соревнования 2020 для «белых хакеров». Ста...</td>\n",
       "      <td>https://habr.com/ru/company/otus/blog/530612/</td>\n",
       "      <td>\\n\\n\\nВ декабре OTUS при поддержке VolgaCTF и ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                              title  \\\n",
       "0  вчера в 23:58  Участвуем в соревновании по Data Science. Перв...   \n",
       "0  вчера в 22:15  Новые ограничения в использовании Docker Hub и...   \n",
       "0  вчера в 19:23                           ESP32 в окружении VSCode   \n",
       "0  вчера в 18:30                           Программа SmartData 2020   \n",
       "0  вчера в 16:07  CTF-соревнования 2020 для «белых хакеров». Ста...   \n",
       "\n",
       "                                              link  \\\n",
       "0                 https://habr.com/ru/post/530628/   \n",
       "0  https://habr.com/ru/company/gitlab/blog/530666/   \n",
       "0                 https://habr.com/ru/post/530638/   \n",
       "0   https://habr.com/ru/company/jugru/blog/530584/   \n",
       "0    https://habr.com/ru/company/otus/blog/530612/   \n",
       "\n",
       "                                                text  \n",
       "0  Привет, Хабр!\\n\\r\\nДавно я не писал никаких ст...  \n",
       "0  Ни для кого уже не новость, что начиная с 2 но...  \n",
       "0  В нескольких следующих статьях я хотел бы дета...  \n",
       "0  \\nМы уже рассказывали Хабру, что новая SmartDa...  \n",
       "0  \\n\\n\\nВ декабре OTUS при поддержке VolgaCTF и ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задание 1.2, необязательная часть с полным текстом статей\n",
    "\n",
    "habr_texts = pd.DataFrame()\n",
    "\n",
    "posts = soup.find_all('article', class_='post')\n",
    "\n",
    "for post in posts:\n",
    "    link = post.find('a', class_=\"post__title_link\").get('href')        # Сначала получим ссылку на полный текст\n",
    "    time.sleep(0.5)    # Добавим задержку\n",
    "    soup_test = BeautifulSoup(requests.get(link).text, 'html.parser')    # Сходим по ссылке\n",
    "    text = soup_test.find('div', class_=\"post__text\").get_text()        # Получим полный текст\n",
    "    \n",
    "    # Проверим все элементы превью, а также полный текст, на вхождение ключевых слов\n",
    "    if any(keyword in post.get_text().lower() for keyword in keywords)\\\n",
    "    or any(keyword in text.lower() for keyword in keywords):\n",
    "        title = post.find('a', class_=\"post__title_link\").get_text()\n",
    "        date = post.find('span', class_=\"post__time\").get_text()\n",
    "        row = {'date': date, 'title': title, 'link':link, 'text': text}\n",
    "        habr_texts = pd.concat([habr_texts, pd.DataFrame([row])])\n",
    "        \n",
    "habr_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://habr.com/ru/all/',\n",
       " 'https://habr.com/ru/all/page2/',\n",
       " 'https://habr.com/ru/all/page3/',\n",
       " 'https://habr.com/ru/all/page4/',\n",
       " 'https://habr.com/ru/all/page5/']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Можно пройти по всем страницам, сформировав их список таким образом, например:\n",
    "all_pages = ['https://habr.com/ru/all/page' + str(i) + '/' for i in range(2, 51)]\n",
    "all_pages.insert(0, url)\n",
    "all_pages[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 23:58</td>\n",
       "      <td>Участвуем в соревновании по Data Science. Перв...</td>\n",
       "      <td>https://habr.com/ru/post/530628/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 22:10</td>\n",
       "      <td>Регламенты закупок: кто виноват, что делать… K...</td>\n",
       "      <td>https://habr.com/ru/post/530668/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 18:30</td>\n",
       "      <td>Программа SmartData 2020</td>\n",
       "      <td>https://habr.com/ru/company/jugru/blog/530584/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 15:58</td>\n",
       "      <td>Как разработать ансамбль Light Gradient Booste...</td>\n",
       "      <td>https://habr.com/ru/company/skillfactory/blog/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 13:59</td>\n",
       "      <td>Snowflake, Anchor Model, ELT и как с этим жить</td>\n",
       "      <td>https://habr.com/ru/company/manychat/blog/530054/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13 ноября 2020 в 11:16</td>\n",
       "      <td>Что в контенте тебе моем? Многовековая эволюци...</td>\n",
       "      <td>https://habr.com/ru/company/skillbox/blog/527868/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13 ноября 2020 в 10:24</td>\n",
       "      <td>Умная нормализация данных: категориальные и по...</td>\n",
       "      <td>https://habr.com/ru/post/527860/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13 ноября 2020 в 09:30</td>\n",
       "      <td>Обзор операторов PostgreSQL для Kubernetes. Ча...</td>\n",
       "      <td>https://habr.com/ru/company/flant/blog/527524/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 ноября 2020 в 19:48</td>\n",
       "      <td>Константин Смирнов: «Барон контракт подписал, ...</td>\n",
       "      <td>https://habr.com/ru/company/dataart/blog/527794/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 ноября 2020 в 19:25</td>\n",
       "      <td>Вычисляем последовательность Фибоначчи за лога...</td>\n",
       "      <td>https://habr.com/ru/company/otus/blog/527766/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              title  \\\n",
       "0            вчера в 23:58  Участвуем в соревновании по Data Science. Перв...   \n",
       "0            вчера в 22:10  Регламенты закупок: кто виноват, что делать… K...   \n",
       "0            вчера в 18:30                           Программа SmartData 2020   \n",
       "0            вчера в 15:58  Как разработать ансамбль Light Gradient Booste...   \n",
       "0            вчера в 13:59     Snowflake, Anchor Model, ELT и как с этим жить   \n",
       "..                     ...                                                ...   \n",
       "0   13 ноября 2020 в 11:16  Что в контенте тебе моем? Многовековая эволюци...   \n",
       "0   13 ноября 2020 в 10:24  Умная нормализация данных: категориальные и по...   \n",
       "0   13 ноября 2020 в 09:30  Обзор операторов PostgreSQL для Kubernetes. Ча...   \n",
       "0   12 ноября 2020 в 19:48  Константин Смирнов: «Барон контракт подписал, ...   \n",
       "0   12 ноября 2020 в 19:25  Вычисляем последовательность Фибоначчи за лога...   \n",
       "\n",
       "                                                 link  \n",
       "0                    https://habr.com/ru/post/530628/  \n",
       "0                    https://habr.com/ru/post/530668/  \n",
       "0      https://habr.com/ru/company/jugru/blog/530584/  \n",
       "0   https://habr.com/ru/company/skillfactory/blog/...  \n",
       "0   https://habr.com/ru/company/manychat/blog/530054/  \n",
       "..                                                ...  \n",
       "0   https://habr.com/ru/company/skillbox/blog/527868/  \n",
       "0                    https://habr.com/ru/post/527860/  \n",
       "0      https://habr.com/ru/company/flant/blog/527524/  \n",
       "0    https://habr.com/ru/company/dataart/blog/527794/  \n",
       "0       https://habr.com/ru/company/otus/blog/527766/  \n",
       "\n",
       "[88 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Все страницы, только превью\n",
    "\n",
    "habr_previews = pd.DataFrame()\n",
    "\n",
    "for page_url in all_pages:\n",
    "    time.sleep(0.5)\n",
    "    soup = BeautifulSoup(requests.get(page_url).text, 'html.parser')\n",
    "    posts = soup.find_all('article', class_='post')\n",
    "    for post in posts:\n",
    "        if any(keyword in post.get_text().lower() for keyword in keywords):\n",
    "            title = post.find('a', class_=\"post__title_link\").get_text()\n",
    "            date = post.find('span', class_=\"post__time\").get_text()\n",
    "            link = post.find('a', class_=\"post__title_link\").get('href')\n",
    "            row = {'date': date, 'title': title, 'link':link}\n",
    "            habr_previews = pd.concat([habr_previews, pd.DataFrame([row])])\n",
    "habr_previews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "### Обязательная часть\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/). Список email-ов задаем переменной в начале кода:  \n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"xxx@x.ru\", \"yyy@y.com\"]\n",
    "url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столкнувшись с несколькими ошибками, скопировал все хедеры из запроса\n",
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'Content-Length': '44',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'vaar-version': '0',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',\n",
    "    'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "    'Content-Type': 'application/json;charset=UTF-8',\n",
    "    'Origin': 'https://www.avast.com',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Referer': 'https://www.avast.com/',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Похоже, сайт принимает на вход json; без него не получается\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payload = {'emailAddresses': emails}\n",
    "req = requests.post(url, headers=headers, data=json.dumps(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xxx@x.ru': {'breaches': [3176, 12, 3, 3164, 2961, 15]},\n",
       " 'yyy@y.com': {'breaches': [16613,\n",
       "   16488,\n",
       "   18155,\n",
       "   17110,\n",
       "   17670,\n",
       "   13094,\n",
       "   13254,\n",
       "   16768,\n",
       "   41,\n",
       "   2,\n",
       "   3587,\n",
       "   17009,\n",
       "   16802,\n",
       "   3,\n",
       "   13662,\n",
       "   3520,\n",
       "   15,\n",
       "   3669]}}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.json()['summary']    # Перечень утечек для адресов - в 'summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breachId': 3176,\n",
       " 'site': 'parapa.mail.ru',\n",
       " 'recordsCount': 5029003,\n",
       " 'description': \"In July and August 2016, two criminals executed attacks against three separate forums hosted by Mail.ru including the Russian forum Parapa. Shortly after the breach occurred, the contents of Parapa's database were leaked publicly. The database contains usernames, email addresses, and hashed passwords for around 5 million users.\",\n",
       " 'publishDate': '2017-02-14T00:00:00Z',\n",
       " 'statistics': {'usernames': 5029000, 'passwords': 5029003, 'emails': 4941344}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.json()['breaches']['3176']    # Подробное описание утечки по id, пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>parapa.mail.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>cdprojektred.com</td>\n",
       "      <td>2017-01-31T00:00:00Z</td>\n",
       "      <td>In March 2016, CDProjektRed.com.com's forum da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>verifications.io</td>\n",
       "      <td>2019-03-28T00:00:00Z</td>\n",
       "      <td>Big data e-mail verification platform verifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>www.dangdang.com</td>\n",
       "      <td>2019-02-21T00:00:00Z</td>\n",
       "      <td>This is a list of email addresses only, and as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>123rf.com</td>\n",
       "      <td>2020-11-19T00:00:00Z</td>\n",
       "      <td>In March 2020, the stock image agency 123RF wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>azcentral.com</td>\n",
       "      <td>2020-01-03T00:00:00Z</td>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>wishbone.io</td>\n",
       "      <td>2020-05-28T00:00:00Z</td>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>myheritage.com</td>\n",
       "      <td>2017-11-04T00:00:00Z</td>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>creocommunity.com</td>\n",
       "      <td>2017-12-01T00:00:00Z</td>\n",
       "      <td>At an unconfirmed date, Creo Community's user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>canva.com</td>\n",
       "      <td>2019-06-13T00:00:00Z</td>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>2016-10-24T00:00:00Z</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>linkedin.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>rayli.com.cn</td>\n",
       "      <td>2017-03-01T00:00:00Z</td>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>zynga.com</td>\n",
       "      <td>2019-10-17T00:00:00Z</td>\n",
       "      <td>In September 2019, the game developer Zynga wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>medicaresupplement.com</td>\n",
       "      <td>2019-07-11T00:00:00Z</td>\n",
       "      <td>In May 2019, a security researcher discovered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>netlog.com</td>\n",
       "      <td>2018-02-18T00:00:00Z</td>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>globalreach.eu</td>\n",
       "      <td>2017-03-15T00:00:00Z</td>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>youku.com</td>\n",
       "      <td>2017-03-24T00:00:00Z</td>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       email                  source                  date  \\\n",
       "0   xxx@x.ru          parapa.mail.ru  2017-02-14T00:00:00Z   \n",
       "0   xxx@x.ru                  vk.com  2016-10-29T00:00:00Z   \n",
       "0   xxx@x.ru               adobe.com  2016-10-21T00:00:00Z   \n",
       "0   xxx@x.ru           cfire.mail.ru  2017-02-14T00:00:00Z   \n",
       "0   xxx@x.ru        cdprojektred.com  2017-01-31T00:00:00Z   \n",
       "0   xxx@x.ru               imesh.com  2016-10-23T00:00:00Z   \n",
       "0  yyy@y.com        verifications.io  2019-03-28T00:00:00Z   \n",
       "0  yyy@y.com        www.dangdang.com  2019-02-21T00:00:00Z   \n",
       "0  yyy@y.com               123rf.com  2020-11-19T00:00:00Z   \n",
       "0  yyy@y.com           azcentral.com  2020-01-03T00:00:00Z   \n",
       "0  yyy@y.com             wishbone.io  2020-05-28T00:00:00Z   \n",
       "0  yyy@y.com          myheritage.com  2017-11-04T00:00:00Z   \n",
       "0  yyy@y.com       creocommunity.com  2017-12-01T00:00:00Z   \n",
       "0  yyy@y.com               canva.com  2019-06-13T00:00:00Z   \n",
       "0  yyy@y.com             dropbox.com  2016-10-24T00:00:00Z   \n",
       "0  yyy@y.com            linkedin.com  2016-10-21T00:00:00Z   \n",
       "0  yyy@y.com            rayli.com.cn  2017-03-01T00:00:00Z   \n",
       "0  yyy@y.com               zynga.com  2019-10-17T00:00:00Z   \n",
       "0  yyy@y.com  medicaresupplement.com  2019-07-11T00:00:00Z   \n",
       "0  yyy@y.com               adobe.com  2016-10-21T00:00:00Z   \n",
       "0  yyy@y.com              netlog.com  2018-02-18T00:00:00Z   \n",
       "0  yyy@y.com          globalreach.eu  2017-03-15T00:00:00Z   \n",
       "0  yyy@y.com               imesh.com  2016-10-23T00:00:00Z   \n",
       "0  yyy@y.com               youku.com  2017-03-24T00:00:00Z   \n",
       "\n",
       "                                         description  \n",
       "0  In July and August 2016, two criminals execute...  \n",
       "0  Popular Russian social networking platform VKo...  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  In July and August of 2016, two criminals carr...  \n",
       "0  In March 2016, CDProjektRed.com.com's forum da...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  Big data e-mail verification platform verifica...  \n",
       "0  This is a list of email addresses only, and as...  \n",
       "0  In March 2020, the stock image agency 123RF wa...  \n",
       "0  At an unconfirmed date, online Arizona newspap...  \n",
       "0  In January 2020, the online poll website Wishb...  \n",
       "0  In October 2017, a customer database belonging...  \n",
       "0  At an unconfirmed date, Creo Community's user ...  \n",
       "0  In May 2019, graphic-design site Canva's datab...  \n",
       "0  Cloud storage company Dropbox suffered a major...  \n",
       "0  In 2012, online professional networking platfo...  \n",
       "0  On an unconfirmed date, Chinese gossip site Ra...  \n",
       "0  In September 2019, the game developer Zynga wa...  \n",
       "0  In May 2019, a security researcher discovered ...  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  Netlog (formerly known as Facebox and Bingbox)...  \n",
       "0  In 2016, Global Reach Technology's database wa...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  Youku is a large Chinese video content company...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_breaches = pd.DataFrame()\n",
    "\n",
    "for email, ids in req.json()['summary'].items():\n",
    "    breach_ids = ids['breaches']    # Список id утечек из json 'summary'\n",
    "    \n",
    "    # Если список утечек для адреса не пустой, вытаскиваем подробную информацию из json для каждого id\n",
    "    if breach_ids:\n",
    "        for breach_id in breach_ids:\n",
    "            breach = req.json()['breaches'][str(breach_id)]\n",
    "            row = {'email': email, 'source': breach['site'], \n",
    "                   'date': breach['publishDate'], 'description': breach['description']}\n",
    "            email_breaches = pd.concat([email_breaches, pd.DataFrame([row])])\n",
    "\n",
    "email_breaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)\n",
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.  \n",
    "Документация к API VK: [https://vk.com/dev/methods](https://vk.com/dev/methods) , вам поможет метод wall.get\n",
    "\n",
    "GROUP = 'netology'  \n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ  \n",
    "В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
